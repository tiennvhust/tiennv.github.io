<!DOCTYPE html>
<html>
  <head>
    <title>Tien V Nguyen</title>
    <link rel="stylesheet" href="style/navstyle.css">
    <link rel="stylesheet" href="style/textstyle.css">
    <link rel="stylesheet" href="style/style.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
  </head>
  <body>
        <div id="navbar">
            <a href="#About">About</a>
            <a href="#Projects">Projects</a>
            <a href="#Contact">Contact</a>
        </div>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <!-- Add all page content inside this div if you want the side nav to push page content to the right (not used if you only want the sidenav to sit on top of the page -->
        <div class="background">
            <div class="about" id="About">
                <h1>Tien Van Nguyen</h1>
                <p>A postgraduate research student in Electrical and Electronics Engineering, having two years of working and research experience in embedded software engineering, robotics, digital signal processing, and machine learning.</p>
            </div>
        </div>
        <div class="main">
            <!-- EDUCATION -->
            <div class="cvsection">
                <h2>Education</h2>
                <!-- UCC -->
                <h3>University College Cork</h3>
                <p style="text-align:left;">
                    Cork, Ireland
                    <span style="float:right;">
                        May 2022 ‑ Current
                    </span>
                </p>
                <h4>MSc ‑ Electrical and Electronics Engineering</h4>
                <!-- TUM -->
                <h3>Technical University of Munich</h3>
                <p style="text-align:left;">
                    Munich, Germany
                    <span style="float:right;">
                        Oct 2019 ‑ Apr 2020
                    </span>
                </p>
                <h4>Exchange Student</h4>
                <!-- HUST -->
                <h3>Hanoi University of Science and Technology</h3>
                <p style="text-align:left;">
                    Hanoi, Vietnam
                    <span style="float:right;">
                        Oct 2015 ‑ Aug 2020
                    </span>
                </p>
                <h4>Engineer ‑ Control Engineering and Automation</h4>
            </div>
            <!-- EXPERIENCE -->
            <div class="cvsection">
                <h2>Work Experience</h2>
                <!-- VKIST -->
                <h3>Vietnam – Korea Institute of Science and Technology</h3>
                <p style="text-align:left;">
                    Hanoi, Vietnam
                    <span style="float:right;">
                        Aug 2021 ‑ Apr 2022
                    </span>
                </p>
                <h4>Research Engineer</h4>
                <!-- VIETTELTECH -->
                <!-- VKIST -->
                <h3>Viettel High Technology Industries Corporation</h3>
                <p style="text-align:left;">
                    Hanoi, Vietnam
                    <span style="float:right;">
                        Nov 2020 ‑ Aug 2021
                    </span>
                </p>
                <h4>Embedded Software Engineer</h4>
            </div>
            <div class="cvsection" id="Projects">
                <h2>Projects</h2>
                <h3 class="collapsible">Omnidirectional Robot Prototype Development</h3>
                <div id="project1">
                    <h4>DESCRIPTION</h4>
                    <p>Developing an omnidirectional robot prototype for research and development of a navigation system for field robots.</p>
                    <h4>CONTRIBUTIONS</h4>
                    <p>I designed the electrical system, safety management system, actuator control software, and graphical user interface.</p>
                    <ol>
                        <b><li>Actuator Control Software</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>I designed and developed a software to control BLDC motor drivers, which control the robot wheels. Control and query commands are sent to motor driver via an UART communication port. The main language used was C/C++ with Robot Operating System (ROS).<br>Source code: <a href="https://github.com/tiennvhust/bldc_driver">here</a></p>
                          </div>
                          <div class="video-box">
                            <video controls>
                              <source src="../videos/1683561766185.MP4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                          </div>
                        </div>
                        <b><li>Graphical User Interface</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>I designed and developed robot Graphical User Interface (GUI) using Qt Creator software. This GUI allows users to control the movement of the robot via a software joystick, displays robot's data and status. The main language used was C/C++ with Qt Creator and Robot Operating System (ROS).<br>Source code: <a href="https://github.com/tiennvhust/vk_omni_gui">here</a></p>
                          </div>
                          <div class="video-box">
                            <video controls>
                              <source src="https://user-images.githubusercontent.com/95061513/160900081-84f24e7f-518d-42c9-aed3-01580d267aa2.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                          </div>
                        </div>
                        <b><li>Safety Management System</li></b>
                        <p>I designed a safety mechanism using a PLC and software to control the operation of the robot. The development of this system involving PLC programing and C/C++ with ROS.<br>Source code: <a href="https://github.com/tiennvhust/vk_omni_plc">here</a></p>
                    </ol>
                  </div>
                  <!-- Project 2 -->
                  <h3 class="collapsible">Real-time, AI-assisted Sonification Algorithm for Neonatal EEG</h3>
                  <div id="project2">
                    <h4>DESCRIPTION</h4>
                    <p>Neonatal seizures are a critical problem globally, which can lead to long-term developmental and neurological disabilities or even death. Early detection of seizures is crucial for preventing these outcomes by enabling timely intervention. However, clinical detection of neonatal seizures is challenging due to the lack of physical symptoms and limited access to experts in EEG analysis. Artificial Intelligence (AI) has emerged as a popular tool to assist medical professionals in interpreting EEG signals and detecting seizures. A novel method of AI-assisted EEG sonification was introduced to compensate for the lack of explainability in AI’s decisions. This method uses sound to detect seizures intuitively while exploiting AI’s effectiveness as an attention mechanism. Besides low power consumption, the real-time operating capability is also essential for adapting this algorithm in clinical settings, which is unattainable with the offline processing approach used in previous studies. This study presents a scalable and real-time adaptation of this algorithm with an ultra-low power implementation. This application provides continuous audio output for medical workers, allowing for immediate access to audio analysis of the EEG signals. An on-chip ultra-low power neural network accelerator enables the implementation to scale up the number of monitored EEG channels. The real-time algorithm has an average power consumption of 13 milliwatts, allowing it to operate for more than eleven days on a mobile phone battery with a capacity of 3500 mAh.</p>
                    <ol>
                        <b><li>Original AI-assited Sonification Algorithm</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>A novel method of AI-driven spatial neonatal EEG sonification has been presented in [1]. It utilizes the Phase Vocoder (PV) algorithm with an AI-guided time-compression factor as an attention mechanism. The AI probabilities are used to modulate the audio playback speed, maintaining focus on the EEG regions with a high probability of seizures, while allowing quick audio rendering over non-seizure EEG segments. This method combines the accuracy and speed of AI algorithms with the interpretability and intuitiveness of sonification, it enables a quick, accurate, and interpretable seizure detection method while requiring little to no training from medical workers.</p>
                          </div>
                          <div class="video-box">
                            <img src="../images/original.gif" style="width:400px;">
                          </div>
                        </div>
                        <b><li>Real-Time Adaptation</li></b>
                        <div class="video-container">
                          <div class="video-box">
                            <p>This study presents a real-time adaptation of the AI-assisted EEG sonification algorithm and its implementation on an ultra-low power embedded system. A significant advantage of a real-time implementation is that the output audio is always available for listening. Medical workers can have access to real-time audio at any time without having to periodically restart the sonification algorithm, enabling seizure detection as soon as they occur. This ultra-low-power implementation is suitable for wearable devices, which can be widely adopted in clinical settings, including Intensive Care Units, for continuous neonatal EEG monitoring.</p>
                          </div>
                          <div class="video-box">
                            <img src="../images/realtime.gif" style="width:400px;">
                          </div>
                        </div>
                    </ol>
                    <h4>Deep Learning Algorithm Quantization</h4>
                    <p>Before the model can be deployed on the MAX78002’s deep neural network accelerator, its parameters must be quantized to 8-bit integers. In practice, there are two main techniques for quantization: Post Training Quantization (PTQ) and Quantization Aware Training (QAT). On the one hand, PTQ can be used to quantize a pre-trained model without any re-training requirements. QAT on the other hand immensely improves the post-quantization performance. The dataset used for quantization aware training and validation is a public dataset of neonatal EEG provided by the Helsinki University Hospital [2]. This dataset is split into a trainset of 39 neonates and a test set of 40 neonates, each dataset contains approximately the same percentage of seizures.<br>Table I compares the performance of the original model and its 8-bits integer version against the test set. The results showed that the quantized model has a 0.8% drop in Area under the ROC Curve (AUC). However, by converting the model from 32-bit floating point into 8-bit integer the size of the model was reduced by 75% and the inference speed is significantly increased.</p>
                    <table>
                      <caption>TABLE I. 	POST QUANTIZATION PERFORMANCE</caption>
                      <tr>
                        <th>Model</th>
                        <th>Bit-width</th>
                        <th>Number of Parameters</th>
                        <th>Size (bytes)</th>
                        <th>AUC (%)</th>
                      </tr>
                      <tr>
                        <td>Original</td>
                        <td>32</td>
                        <td>25,156</td>
                        <td>102,152</td>
                        <td>95.4</td>
                      </tr>
                      <tr>
                        <td>Quantized</td>
                        <td>8</td>
                        <td>25,156</td>
                        <td>25,156</td>
                        <td>94.6</td>
                      </tr>
                    </table>
                    <h4>REFERENCES</h4>
                    <p>[1]&nbsp;S. Gomez-Quintana, A. O’Shea, A. Factor, E. Popovici, and A. Temko, “A method for AI assisted human interpretation of neonatal EEG,” Sci Rep, vol. 12, no. 1, p. 10932, 2022, doi: 10.1038/s41598-022-14894-4.<br>[2]&nbsp;N. Stevenson, K. Tapani, L. Lauronen, and S. Vanhatalo, “A dataset of neonatal EEG recordings with seizures annotations,” Jun. 2018, doi: 10.5281/ZENODO.2547147.</p>
                  </div>
            </div>
        </div>
        <script src="scripts/script.js"></script>
        <script src="scripts/navscript.js"></script>
        <div class="background">
          <div class="contact" id="Contact">
              <p>nguyentien97.hust@gmail.com</p>
          </div>
        </div>
  </body>
</html>